#to run postgres in docker need its environment by using -e
#mapping folder in host machine file system to folder in container 
#use whatever version of postgres installed locally on ur machine postgres --version
#for port use 5431:5432 to avoid conflict with local postgres
#This maps port 5431 on the host to port 5432 inside the container.
#PostgreSQL listens on port 5432 by default, so you need to map it a new port like 5431.
docker run -it \
    -e POSTGRES_USER="root" \
    -e POSTGRES_PASSWORD="root" \
    -e POSTGRES_DB="ny_taxi" \
    -v pwd(c:/.....)/ny_taxi_postgres_data:/var/lib/postgresql/data \
    -p 5431:5432 \
    postgres:16


pgcli -h localhost -p 5431 -u root -d ny_taxi
pgcli --help to view all commands
# -h hostname -p port_no -u username -d database_name we set above
https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
#Schema for table
https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf

#to run pgadmin in docker
docker run -it \
    -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
    -e PGADMIN_DEFAULT_PASSWORD="root" \
    -p 8080:80 \
    dpage/pgadmin4

#now this pgadmin and database are not connected to same network so we need to connect them
docker network create pg-network
docker run -it \
    -e POSTGRES_USER="root" \
    -e POSTGRES_PASSWORD="root" \
    -e POSTGRES_DB="ny_taxi" \
    -v c:/Users/blim0/Desktop/data_zoomcamp/01_intro_to_docker/ny_taxi_postgres_data:/var/lib/postgresql/data \
    -p 5431:5432 \
    --network=pg-network \
    --name pg-database \
    postgres:16

#go localhost:8080 in browser to access pgadmin db for this docker
docker run -it \
    -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
    -e PGADMIN_DEFAULT_PASSWORD="root" \
    -p 8080:80 \
    --network=pg-network \
    --name pgadmin \
    dpage/pgadmin4


#convert noteboook to python but still need edits
jupyter nbconvert --to=script upload-data.ipynb


#run ingest data pipeline
#not the safest way to pass password as bash history command will be safed and can leak
#pass through environment variable or more secure way
#host in future will be in docker

URL="https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet"

python ingest-data.py \
  --user=root \
  --password=root \
  --host=localhost \
  --port=5431 \
  --db=ny_taxi \
  --table_name=yellow_taxi_trips \
  --url=${URL}

#to run the ingest-data in docker container we need to build the container
# to contain those python scripts and dependencies needed from  pip install
docker build -t taxi_ingest:v001 .

#once build finish, we than run that docker container
# without network pg-network it runs just within localhost container without pgadmin
URL="https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet"

#in future the host instead of local pg-database will be some online cloud like big query
docker run -it \
    --network=pg-network \
    taxi_ingest:v001 \
        --user=root \
        --password=root \
        --host=pg-database \
        --port=5432 \
        --db=ny_taxi \
        --table_name=yellow_taxi_trips \
        --url=${URL}

#using docker compose YAML allow us to put configuration of multiple containers in one file